{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"off white in python\"\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException, ElementNotInteractableException, NoSuchWindowException, InvalidSessionIdException\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "import openpyxl\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, display_html\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "from tensorflow.python.framework import ops\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from typing import Any, List, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printd(str):\n",
    "    global DEBUG\n",
    "    if DEBUG:\n",
    "        print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(barnum):\n",
    "    #debugging flag\n",
    "    if barnum == 1:\n",
    "        printd(\"*******************************************************************\")\n",
    "    if barnum ==2:\n",
    "        printd(\":::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tile():\n",
    "    def __init__(\n",
    "        self,\n",
    "        cordinates,\n",
    "        value):\n",
    "        printd(cordinates)\n",
    "        for val in range(len(cordinates)):\n",
    "            cordinates[val] = tf.cast(int(cordinates[val]), dtype = tf.int64)\n",
    "            cordinates[val] -= 1\n",
    "        x = cordinates[0]\n",
    "        y = cordinates[1]\n",
    "        cordinates = [y, x]\n",
    "        self.cordinates = cordinates\n",
    "        self.value = int(value)\n",
    "    def __str__(self):\n",
    "        return self.value, self.cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtiles(tile1, tile2):\n",
    "    #used in the testing version of the game\n",
    "    tile3value = tile1.value + tile2.value\n",
    "    tile3cordinates = [tile1.cordinates[1] + 1, tile1.cordinates[0] + 1]\n",
    "    tile3 = Tile(tile3cordinates, tile3value)\n",
    "    return tile3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadsite():\n",
    "    driver.get(\"https://play2048.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcordinates(tilediv):\n",
    "    #used in the testing version to scrape tiles cords from html element\n",
    "    tiledivclass = tilediv.get_attribute(\"class\")\n",
    "    printd(tiledivclass)\n",
    "    cordsindex = tiledivclass.index(\"tile-position\") + 14\n",
    "    cordsstr = tiledivclass[cordsindex:]\n",
    "    cordsstr = cordsstr.split(\" \")\n",
    "    cords = cordsstr[0]\n",
    "    cords = cords.split(\"-\")\n",
    "    printd(\"these are cords the cords for tilediv:\" + tiledivclass)\n",
    "    printd(cords)\n",
    "    for cord in cords:\n",
    "        cord = int(cord)\n",
    "    return cords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettiles(tilelist, y, x):\n",
    "    cordtiles = []\n",
    "    for tile in tilelist:\n",
    "        if tile.cordinates == [y, x]:\n",
    "            cordtiles.append(tile)\n",
    "    return cordtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatetiles(tiledivs):\n",
    "    tilelist = []\n",
    "    for tilediv in tiledivs:\n",
    "        tiledivclass = tilediv.get_attribute(\"class\")\n",
    "        if \"tile-merged\" in tiledivclass:\n",
    "            continue\n",
    "        value = int(tilediv.text)\n",
    "        printd(\"this is the value: \" + str(value))\n",
    "        cordinates = getcordinates(tilediv)\n",
    "        tile = Tile(cordinates, value)\n",
    "        tilelist.append(tile)\n",
    "    tile1index = 0\n",
    "    printd(\"this is the num tiles\")\n",
    "    printd(len(tilelist))\n",
    "    matchedindexs = []\n",
    "    tilelistcopy = tilelist\n",
    "    for y in range(4):\n",
    "        for x in range(4):\n",
    "            cordtiles = gettiles(tilelist, y, x)\n",
    "            if len(cordtiles) > 1:\n",
    "                assert(len(cordtiles) < 3)\n",
    "                tilelist.remove(cordtiles[0])\n",
    "                tilelist.remove(cordtiles[1])\n",
    "                tilelist.append(addtiles(cordtiles[0], cordtiles[1]))\n",
    "    printd(\"this is our tile list\")\n",
    "    for tile in tilelist:\n",
    "        printd(tile.__str__())\n",
    "    printd('these are our matched indices')\n",
    "    printd(matchedindexs)\n",
    "    return tilelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getboard():\n",
    "    boardshape = [4, 4]\n",
    "    boardtensor = tf.zeros(boardshape, dtype = np.int64)\n",
    "    while True:\n",
    "        try:\n",
    "            board = driver.find_element_by_class_name(\"tile-container\")\n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            time.sleep(0.5)\n",
    "    tiledivs = board.find_elements_by_tag_name(\"div\")\n",
    "    for tilediv in tiledivs:\n",
    "        if tilediv.get_attribute(\"class\") == \"tile-inner\":\n",
    "            tiledivs.remove(tilediv)\n",
    "    tiles = generatetiles(tiledivs)\n",
    "    indices = []\n",
    "    values = []\n",
    "    for tile in tiles:\n",
    "        indices.append(tile.cordinates)\n",
    "        values.append(tile.value)\n",
    "    printd(\"ATTEMPTING TO CREATE SPARSE TENSOR WITH THESE INDICES\")\n",
    "    printd(indices)\n",
    "    indices = tf.cast(indices, dtype = np.int64)\n",
    "    values = tf.cast(values, dtype = np.int64)\n",
    "    printd(\"AND THESE VALUES\")\n",
    "    printd(values)\n",
    "    delta = tf.SparseTensor(indices, values, boardshape)\n",
    "    delta = tf.sparse.reorder(delta)\n",
    "    boardtensor = tf.cast(boardtensor, dtype = np.int64)\n",
    "    board = boardtensor + tf.sparse.to_dense(delta)\n",
    "    printd(board)\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatevalidlist(board, action_logits):\n",
    "    moveupwards = False\n",
    "    movedownwards = False\n",
    "    moveleft = False\n",
    "    moveright = False\n",
    "    for x in range(4):\n",
    "        prevboardval = None\n",
    "        foundnum = False\n",
    "        foundzero = False\n",
    "        for y in range(4):\n",
    "            #foundnum and foundzero refer to if we have ever seen a number or zero in the row\n",
    "            if board[y, x] != 0:\n",
    "                foundnum = True\n",
    "            else:\n",
    "                foundzero = True\n",
    "            if ((board[y, x] == 0) and foundnum):\n",
    "                movedownwards = True\n",
    "            if ((board[y, x] != 0 and foundzero)):\n",
    "                moveupwards = True\n",
    "            if board[y, x] == prevboardval and (prevboardval != 0):\n",
    "                moveupwards = True\n",
    "                movedownwards = True\n",
    "            prevboardval = board[y, x]\n",
    "    for y in range(4):\n",
    "        prevboardval = None\n",
    "        foundnum = False\n",
    "        foundzero = False\n",
    "        for x in range(4):\n",
    "            #foundnum and foundzero refer to if we have ever seen a number or zero in the row\n",
    "            if board[y, x] != 0:\n",
    "                foundnum = True\n",
    "            else:\n",
    "                foundzero = True\n",
    "            if ((board[y, x] == 0) and foundnum):\n",
    "                moveright = True\n",
    "            if ((board[y, x] != 0 and foundzero)):\n",
    "                moveleft = True\n",
    "            if board[y, x] == prevboardval and (prevboardval != 0):\n",
    "                moveright = True\n",
    "                moveleft = True\n",
    "            prevboardval = board[y, x]\n",
    "    #list for values will be in order of 0: up, 1: down, 2: right, 3: left\n",
    "    values = []\n",
    "    indices = []\n",
    "    shape = [1, 4]\n",
    "    if not moveupwards:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE UP\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 0])\n",
    "    if not movedownwards:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE DOWN\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 1])\n",
    "    if not moveright:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE RIGHT\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 2])\n",
    "    if not moveleft:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE LEFT\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 3])\n",
    "    if values != []:\n",
    "        delta = tf.SparseTensor(indices, values, shape)\n",
    "        action_logits = tf.reshape(action_logits, shape)\n",
    "        action_logits = action_logits + tf.sparse.to_dense(delta)\n",
    "    printd(\"these are our new action logits\")\n",
    "    printd(action_logits)\n",
    "    return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatetrainingvalidlist(board, action_logits):\n",
    "    moveupwards = False\n",
    "    movedownwards = False\n",
    "    moveleft = False\n",
    "    moveright = False\n",
    "    done = False\n",
    "    for x in range(4):\n",
    "        prevboardval = None\n",
    "        foundnum = False\n",
    "        foundzero = False\n",
    "        for y in range(4):\n",
    "            #foundnum and foundzero refer to if we have ever seen a number or zero in the row\n",
    "            if board[y, x] != 0:\n",
    "                foundnum = True\n",
    "            else:\n",
    "                foundzero = True\n",
    "            if ((board[y, x] == 0) and foundnum):\n",
    "                movedownwards = True\n",
    "            if ((board[y, x] != 0 and foundzero)):\n",
    "                moveupwards = True\n",
    "            if board[y, x] == prevboardval and (prevboardval != 0):\n",
    "                moveupwards = True\n",
    "                movedownwards = True\n",
    "            prevboardval = board[y, x]\n",
    "    for y in range(4):\n",
    "        prevboardval = None\n",
    "        foundnum = False\n",
    "        foundzero = False\n",
    "        for x in range(4):\n",
    "            #foundnum and foundzero refer to if we have ever seen a number or zero in the row\n",
    "            if board[y, x] != 0:\n",
    "                foundnum = True\n",
    "            else:\n",
    "                foundzero = True\n",
    "            if ((board[y, x] == 0) and foundnum):\n",
    "                moveright = True\n",
    "            if ((board[y, x] != 0 and foundzero)):\n",
    "                moveleft = True\n",
    "            if board[y, x] == prevboardval and (prevboardval != 0):\n",
    "                moveright = True\n",
    "                moveleft = True\n",
    "            prevboardval = board[y, x]\n",
    "    #list for values will be in order of 0: up, 1: down, 2: right, 3: left\n",
    "    values = []\n",
    "    indices = []\n",
    "    shape = [1, 4]\n",
    "    if not moveupwards:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE UP\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 0])\n",
    "    if not movedownwards:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE DOWN\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 1])\n",
    "    if not moveright:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE RIGHT\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 2])\n",
    "    if not moveleft:\n",
    "        printd(\"SCRIPT THINKS WE CANT MOVE LEFT\")\n",
    "        values.append(float(-50000))\n",
    "        indices.append([0, 3])\n",
    "    if (not moveleft and not moveright) and (not moveupwards and not movedownwards):\n",
    "        done = True\n",
    "    if values != []:\n",
    "        delta = tf.SparseTensor(indices, values, shape)\n",
    "        action_logits = tf.reshape(action_logits, shape)\n",
    "        action_logits = action_logits + tf.sparse.to_dense(delta)\n",
    "    printd(\"these are our new action logits\")\n",
    "    printd(action_logits)\n",
    "    return action_logits, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalboard(score):\n",
    "    printd(\"EVALUATING BOARD\")\n",
    "    while True:\n",
    "        try:\n",
    "            newscore = int(driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/div[1]\").text)\n",
    "            break\n",
    "        except ValueError:\n",
    "            continue\n",
    "    reward = newscore - score\n",
    "    printd(\"THIS IS REWARD\")\n",
    "    printd(reward)\n",
    "    done = False\n",
    "    time.sleep(0.5)\n",
    "    try:\n",
    "        loserbtn = driver.find_element_by_class_name(\"retry-button\")\n",
    "        loserbtn.click()\n",
    "        done = True\n",
    "    except ElementNotInteractableException:\n",
    "        printd(\"we can keep going\")\n",
    "    return reward, done, newscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domove(action, score):\n",
    "    while True:\n",
    "        try:\n",
    "            board = driver.find_element_by_tag_name(\"body\")\n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            time.sleep(0.5)\n",
    "    if action == 0:\n",
    "        key = Keys.UP\n",
    "    if action == 1:\n",
    "        key = Keys.DOWN\n",
    "    if action == 2:\n",
    "        key = Keys.RIGHT\n",
    "    if action == 3:\n",
    "        key = Keys.LEFT\n",
    "    board.send_keys(key)\n",
    "    reward, done, score = evalboard(score)\n",
    "    return reward, done, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restartgame():\n",
    "    while True:\n",
    "        try:\n",
    "            loserbtn = driver.find_element_by_class_name(\"retry-button\")\n",
    "        except NoSuchElementException:\n",
    "            time.sleep(0.5)\n",
    "            pass\n",
    "    loserbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "    \"\"\"Combined actor-critic network.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_actions: int, \n",
    "        num_hidden_units: int,\n",
    "        num_hidden_inner: int):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.common = layers.Dense(num_hidden_units, activation=\"relu\")\n",
    "        #self.hidden = layers.Dense(num_hidden_inner)\n",
    "        #self.hidden1 = layers.Dense(num_hidden_inner)\n",
    "        self.actor = layers.Dense(num_actions)\n",
    "        self.critic = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        x = self.common(inputs)\n",
    "        #x = self.hidden(x)\n",
    "        #x = self.hidden1(x)\n",
    "        return self.actor(x), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode( \n",
    "    model: tf.keras.Model) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"Runs a single episode to collect training data.\"\"\"\n",
    "\n",
    "    action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "\n",
    "    score = 0\n",
    "    index = 0\n",
    "    while True:\n",
    "        # Convert state into a batched tensor (batch size = 1)\n",
    "        state = getboard()\n",
    "        modelstate = tf.reshape(state, [1, 16])\n",
    "        # Run the model and to get action probabilities and critic value\n",
    "        action_logits_t, value = model(modelstate)\n",
    "\n",
    "        # Sample next action from the action probability distribution\n",
    "        used_logits = generatevalidlist(state, action_logits_t)\n",
    "        action = tf.random.categorical(used_logits, 1)[0, 0]\n",
    "        action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "        printd(\"action probs\")\n",
    "        printd(action_probs_t)\n",
    "        # Store critic values\n",
    "        values = values.write(index, tf.squeeze(value))\n",
    "\n",
    "        # Store log probability of the action chosen\n",
    "        action_probs = action_probs.write(index, action_probs_t[0, action])\n",
    "\n",
    "        # Apply action to the environment to get next state and reward\n",
    "        reward, done, score = domove(action, score)\n",
    "\n",
    "        # Store reward\n",
    "        rewards = rewards.write(index, reward)\n",
    "        index += 1\n",
    "        #write done identifier\n",
    "        if done:\n",
    "            break\n",
    "    action_probs = action_probs.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "\n",
    "    return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateboard():\n",
    "    boardshape = [4, 4]\n",
    "    boardtensor = tf.zeros(boardshape, dtype = np.int64)\n",
    "    indices = []\n",
    "    values = []\n",
    "    indicecounter = 0\n",
    "    while True:\n",
    "        indice = [random.randint(0, 3), random.randint(0, 3)]\n",
    "        if indice not in indices:\n",
    "            indices.append(indice)\n",
    "            indicecounter += 1\n",
    "            if indicecounter == 2:\n",
    "                break\n",
    "    values.append(2*random.randint(1,2))\n",
    "    values.append(2*random.randint(1,2))\n",
    "    indices = tf.cast(indices, dtype = np.int64)\n",
    "    values = tf.cast(values, dtype = np.int64)\n",
    "    delta = tf.SparseTensor(indices, values, boardshape)\n",
    "    delta = tf.sparse.reorder(delta)\n",
    "    boardtensor = tf.cast(boardtensor, dtype = np.int64)\n",
    "    board = boardtensor + tf.sparse.to_dense(delta)\n",
    "    printd(board)\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveright(state):\n",
    "    rowdict = {}\n",
    "    reward = 0\n",
    "    for y in range(4):\n",
    "        #get whatever row were looking at\n",
    "        row = state[y]\n",
    "        rowlist = [row[0], row[1], row[2], row[3]]\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "                printd(y)\n",
    "                printd(x)\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x + 1] == rowlist[x]:\n",
    "                rowlist[x + 1] = rowlist[x] * 2\n",
    "                reward += rowlist[x] * 2\n",
    "                rowlist[x] = 0\n",
    "        #collapse row again\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "        #add new rows into dictionary\n",
    "        rowlist = tf.cast(rowlist, dtype = np.int64)\n",
    "        rowdict[y] = tf.constant(rowlist)\n",
    "    state = tf.Variable([rowdict[0], rowdict[1], rowdict[2], rowdict[3]])\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveleft(state):\n",
    "    rowdict = {}\n",
    "    reward = 0\n",
    "    for y in range(4):\n",
    "        #get whatever row were looking at\n",
    "        row = state[y]\n",
    "        rowlist = [row[3], row[2], row[1], row[0]]\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "                printd(y)\n",
    "                printd(x)\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x + 1] == rowlist[x]:\n",
    "                rowlist[x + 1] = rowlist[x] * 2\n",
    "                reward += rowlist[x] * 2\n",
    "                rowlist[x] = 0\n",
    "        #collapse row again\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "        #add new rows into dictionary\n",
    "        rowlist.reverse()\n",
    "        rowlist = tf.cast(rowlist, dtype = np.int64)\n",
    "        rowdict[y] = tf.constant(rowlist)\n",
    "    state = tf.Variable([rowdict[0], rowdict[1], rowdict[2], rowdict[3]])\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movedown(state):\n",
    "    rowdict = {}\n",
    "    vertrowdict = {}\n",
    "    reward = 0\n",
    "    for y in range(4):\n",
    "        #get whatever row were looking at\n",
    "        rowlist = [state[0, y], state[1, y], state[2, y], state[3, y]]\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "                printd(y)\n",
    "                printd(x)\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x + 1] == rowlist[x]:\n",
    "                rowlist[x + 1] = rowlist[x] * 2\n",
    "                reward += rowlist[x] * 2\n",
    "                rowlist[x] = 0\n",
    "        #collapse row again\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "        #add new rows into dictionary\n",
    "        rowlist = tf.cast(rowlist, dtype = np.int64)\n",
    "        rowdict[y] = tf.constant(rowlist)\n",
    "    for y in range(4):\n",
    "        vertrowdict[y] = [rowdict[0][y], rowdict[1][y], rowdict[2][y], rowdict[3][y]]\n",
    "    state = tf.Variable([vertrowdict[0], vertrowdict[1], vertrowdict[2], vertrowdict[3]])\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveup(state):\n",
    "    rowdict = {}\n",
    "    vertrowdict = {}\n",
    "    reward = 0\n",
    "    for y in range(4):\n",
    "        #get whatever row were looking at\n",
    "        rowlist = [state[3, y], state[2, y], state[1, y], state[0, y]]\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "                printd(y)\n",
    "                printd(x)\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x + 1] == rowlist[x]:\n",
    "                rowlist[x + 1] = rowlist[x] * 2\n",
    "                reward += rowlist[x] * 2\n",
    "                rowlist[x] = 0\n",
    "        #collapse row again\n",
    "        for x in range(2, -1, -1):\n",
    "            if rowlist[x] != 0:\n",
    "                for x1 in range(x, 3):\n",
    "                    if rowlist[x1 + 1] == 0:\n",
    "                        rowlist[x1 + 1] = rowlist[x1]\n",
    "                        rowlist[x1] = 0\n",
    "        #add new rows into dictionary\n",
    "        rowlist.reverse()\n",
    "        rowlist = tf.cast(rowlist, dtype = np.int64)\n",
    "        rowdict[y] = tf.constant(rowlist)\n",
    "    for y in range(4):\n",
    "        vertrowdict[y] = [rowdict[0][y], rowdict[1][y], rowdict[2][y], rowdict[3][y]]\n",
    "    state = tf.Variable([vertrowdict[0], vertrowdict[1], vertrowdict[2], vertrowdict[3]])\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gentile(state):\n",
    "    emptytilelist = []\n",
    "    indices = []\n",
    "    values = [random.randint(1, 2) * 2]\n",
    "    for y in range(4):\n",
    "        for x in range(4):\n",
    "            if state[y, x] == 0:\n",
    "                emptytilelist.append([y, x])\n",
    "    chosentileindex = random.randint(0, len(emptytilelist) - 1)\n",
    "    indices.append(emptytilelist[chosentileindex])\n",
    "    indices = tf.cast(indices, dtype = np.int64)\n",
    "    values = tf.cast(values, dtype = np.int64)\n",
    "    delta = tf.SparseTensor(indices, values, [4, 4])\n",
    "    state = state + tf.sparse.to_dense(delta)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotrainmove(action, state):\n",
    "    if action == 0:\n",
    "        state, reward = moveup(state)\n",
    "    elif action == 1:\n",
    "        state, reward = movedown(state)\n",
    "    elif action == 2:\n",
    "        state, reward = moveright(state)\n",
    "    elif action == 3:\n",
    "        state, reward = moveleft(state)\n",
    "    reward = tf.cast(reward, dtype = np.float32)\n",
    "    state = gentile(state)\n",
    "    return reward, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizetensor(state):\n",
    "    \n",
    "    modelstate = tf.reshape(state, [1, 16])\n",
    "\n",
    "    scaledlist = []\n",
    "    for i in range(16):\n",
    "        if modelstate[0, i] != 0:\n",
    "            scaledlist.append(float(math.log(modelstate[0, i], 2)))\n",
    "        else:\n",
    "            scaledlist.append(float(0))\n",
    "    scaledtensor = tf.Variable(scaledlist)\n",
    "    scaledtensor = tf.cast(scaledtensor, dtype = np.float32)\n",
    "    scaledtensor = tf.reshape(scaledtensor, [1, 16])\n",
    "    return scaledtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizetensorv2(state):\n",
    "    modelstate = tf.reshape(state, [1, 16])\n",
    "    tiledict = {}\n",
    "    for i in range(16):\n",
    "        tilelist = np.zeros(16)\n",
    "        if modelstate[0, i] != 0:\n",
    "            indexnum = int(math.log(modelstate[0, i], 2) - 1)\n",
    "            assert((math.log(modelstate[0, i], 2) - 1) % 1 == 0)\n",
    "            tilelist[indexnum] = 1\n",
    "        tiledict[i] = tilelist\n",
    "    rowzero = tf.constant([tiledict[0], tiledict[1], tiledict[2], tiledict[3]])\n",
    "    rowone = tf.constant([tiledict[4], tiledict[5], tiledict[6], tiledict[7]])\n",
    "    rowtwo = tf.constant([tiledict[8], tiledict[9], tiledict[10], tiledict[11]])\n",
    "    rowthree = tf.constant([tiledict[12], tiledict[13], tiledict[14], tiledict[15]])\n",
    "    binarystate = tf.Variable([rowzero, rowone, rowtwo, rowthree])\n",
    "    binarystate = tf.cast(binarystate, dtype = np.float32)\n",
    "    binarystate = tf.reshape(binarystate, [1, 256])\n",
    "    return binarystate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtrainepisode(\n",
    "    model: tf.keras.Model) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \n",
    "    action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    state = generateboard()\n",
    "    while True:\n",
    "        # Convert state into a batched tensor (batch size = 1)\n",
    "        \n",
    "        modelstate = normalizetensorv2(state)\n",
    "        \n",
    "        # Run the model and to get action probabilities and critic value\n",
    "        action_logits_t, value = model(modelstate)\n",
    "\n",
    "        # Sample next action from the action probability distribution\n",
    "        used_logits, done = generatetrainingvalidlist(state, action_logits_t)\n",
    "        if done:\n",
    "            clear_output()\n",
    "            print(state)\n",
    "            break\n",
    "        action = tf.random.categorical(used_logits, 1)[0, 0]\n",
    "        \n",
    "        action_probs_t = tf.nn.softmax(used_logits)\n",
    "        printd(\"action probs\")\n",
    "        printd(action_probs_t)\n",
    "        # Store critic values\n",
    "        values = values.write(index, tf.squeeze(value))\n",
    "\n",
    "        # Store log probability of the action chosen\n",
    "        \n",
    "        action_probs = action_probs.write(index, action_probs_t[0, action])\n",
    "\n",
    "        # Apply action to the environment to get next state and reward\n",
    "        reward, state = dotrainmove(action, state)\n",
    "\n",
    "        # Store reward\n",
    "        rewards = rewards.write(index, reward)\n",
    "        index += 1\n",
    "    action_probs = action_probs.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "\n",
    "    return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "def get_expected_return(rewards: tf.Tensor, gamma: float, standardize: bool = True) -> tf.Tensor:\n",
    "    eps = np.finfo(np.float32).eps.item()\n",
    "    n = tf.shape(rewards)[0]\n",
    "    returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "    # Start from the end of `rewards` and accumulate reward sums\n",
    "    # into the `returns` array\n",
    "    rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "    discounted_sum = tf.constant(0.0)\n",
    "    discounted_sum_shape = discounted_sum.shape\n",
    "    for i in tf.range(n):\n",
    "        reward = rewards[i]\n",
    "        discounted_sum = reward + gamma * discounted_sum\n",
    "        discounted_sum.set_shape(discounted_sum_shape)\n",
    "        returns = returns.write(i, discounted_sum)\n",
    "    returns = returns.stack()[::-1]\n",
    "\n",
    "    if standardize:\n",
    "        returns = ((returns - tf.math.reduce_mean(returns)) / \n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,  \n",
    "    values: tf.Tensor,  \n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Computes the combined actor-critic loss.\"\"\"\n",
    "    eps = np.finfo(np.float32).eps.item()\n",
    "    values = ((values - tf.math.reduce_mean(values)) / \n",
    "               (tf.math.reduce_std(values) + eps))\n",
    "    advantage = returns - values\n",
    "    print(values)\n",
    "    print(returns)\n",
    "    action_log_probs = tf.math.log(action_probs)\n",
    "    actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "    critic_loss = huber_loss(values, returns)\n",
    "    csvwrite(float(actor_loss), \"loss.csv\")\n",
    "    csvwrite(float(critic_loss), \"criticloss.csv\")\n",
    "    return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: tf.keras.Model, \n",
    "    optimizer: tf.keras.optimizers.Optimizer, \n",
    "    gamma: float,\n",
    "    n: int) -> tf.Tensor:\n",
    "    \"\"\"Runs a model training step.\"\"\"\n",
    "    global TRAINING\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Run the model for one episode to collect training data\n",
    "        if TRAINING:\n",
    "            action_probs, values, rewards = runtrainepisode(\n",
    "            model) \n",
    "        else:\n",
    "            action_probs, values, rewards = run_episode(\n",
    "            model) \n",
    "\n",
    "        # Calculate expected returns\n",
    "        returns = get_expected_return(rewards, gamma)\n",
    "\n",
    "        # Convert training data to appropriate TF tensor shapes\n",
    "        action_probs, values, returns = [\n",
    "        tf.expand_dims(x, 1) for x in [action_probs, values, returns]] \n",
    "\n",
    "        # Calculating loss values to update our network\n",
    "        loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "    # Compute the gradients from the loss\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the model's parameters\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    episode_reward = tf.math.reduce_sum(rewards)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"------------------------finished game--------------------------\")\n",
    "    print(\"loss: \" + str(loss))\n",
    "    assert(episode_reward < 20000)\n",
    "    print(\"this was our episode_reward: \" + str(episode_reward))\n",
    "    printd(\"These are the gradients we're applying:\")\n",
    "    printd(grads)\n",
    "    csvwrite(float(episode_reward), \"episodereward.csv\")\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvwrite(stat, strfilename):\n",
    "    file = open(strfilename, 'a')\n",
    "    file.write(str(stat) + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphcsv(strfilename, color, label, batchsize):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(strfilename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile, delimiter=',')\n",
    "        counter = 0\n",
    "        for row in lines:\n",
    "            if counter == 0:\n",
    "                val = float(row[0])\n",
    "            elif counter % batchsize == 0: \n",
    "                x.append(counter)\n",
    "                y.append(val/batchsize)\n",
    "                val = 0\n",
    "            else:\n",
    "                val += float(row[0])\n",
    "            counter += 1\n",
    "    plt.plot(x, y, color = color, linestyle = 'dashed', marker = 'o', \n",
    "             label = label)\n",
    "    plt.xticks(rotation = 25)\n",
    "    plt.xlabel(\"game\")\n",
    "    plt.ylabel(label)\n",
    "    plt.title(label, fontsize = 20)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showstats():\n",
    "    graphcsv('episodereward.csv', 'g', \"Episode Reward\", 1000)\n",
    "    graphcsv('loss.csv', 'r', \"Actor Loss\", 1000)\n",
    "    graphcsv('criticloss.csv', 'b', \"Critic Loss\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtest():\n",
    "    showstats()\n",
    "    state = generateboard()\n",
    "    while True:\n",
    "        action = int(input())\n",
    "        reward, state = dotrainmove(action, state)\n",
    "        clear_output()\n",
    "        print(state)\n",
    "        print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  4   2   8  32]\n",
      " [  8  16  32  64]\n",
      " [  2  32   4   2]\n",
      " [  4   8  64 128]], shape=(4, 4), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 1.0629935 ]\n",
      " [ 1.058041  ]\n",
      " [ 1.1158893 ]\n",
      " [ 1.1158966 ]\n",
      " [ 1.0693779 ]\n",
      " [ 1.0760354 ]\n",
      " [ 1.0862448 ]\n",
      " [ 1.077574  ]\n",
      " [ 1.0798346 ]\n",
      " [ 1.1057521 ]\n",
      " [ 1.1031353 ]\n",
      " [ 1.1160406 ]\n",
      " [ 1.1159708 ]\n",
      " [ 1.1456876 ]\n",
      " [ 1.0851387 ]\n",
      " [ 1.1294916 ]\n",
      " [ 1.1240164 ]\n",
      " [ 1.1175964 ]\n",
      " [ 1.1340692 ]\n",
      " [ 1.1154021 ]\n",
      " [ 1.1013656 ]\n",
      " [ 1.0861092 ]\n",
      " [ 1.0719197 ]\n",
      " [ 1.0455885 ]\n",
      " [ 1.0808898 ]\n",
      " [ 1.1139762 ]\n",
      " [ 1.1262743 ]\n",
      " [ 1.1104944 ]\n",
      " [ 0.98798144]\n",
      " [ 0.9975053 ]\n",
      " [ 1.0313666 ]\n",
      " [ 1.0258157 ]\n",
      " [ 1.0734429 ]\n",
      " [ 0.99844617]\n",
      " [ 1.0219884 ]\n",
      " [ 0.9183944 ]\n",
      " [ 0.8966765 ]\n",
      " [ 0.9696822 ]\n",
      " [ 0.9141448 ]\n",
      " [ 0.7473889 ]\n",
      " [ 0.7411359 ]\n",
      " [ 0.72927433]\n",
      " [ 0.6920555 ]\n",
      " [ 0.75247055]\n",
      " [ 0.84456646]\n",
      " [ 0.7896461 ]\n",
      " [ 0.7469469 ]\n",
      " [ 0.7054482 ]\n",
      " [ 0.7253565 ]\n",
      " [ 0.66957146]\n",
      " [ 0.6718186 ]\n",
      " [ 0.6452123 ]\n",
      " [ 0.6423093 ]\n",
      " [ 0.6161911 ]\n",
      " [ 0.7353313 ]\n",
      " [ 0.62324697]\n",
      " [ 0.61150193]\n",
      " [ 0.6207835 ]\n",
      " [ 0.6522258 ]\n",
      " [ 0.62773675]\n",
      " [ 0.5714203 ]\n",
      " [ 0.6302328 ]\n",
      " [ 0.52980596]\n",
      " [ 0.55986   ]\n",
      " [ 0.68895465]\n",
      " [ 0.5305046 ]\n",
      " [ 0.47789332]\n",
      " [ 0.43809894]\n",
      " [ 0.32525977]\n",
      " [ 0.35803232]\n",
      " [ 0.36309633]\n",
      " [ 0.24075584]\n",
      " [-0.18866198]\n",
      " [-0.1834997 ]\n",
      " [-0.25575015]\n",
      " [-0.20825168]\n",
      " [-0.24501829]\n",
      " [-0.22134994]\n",
      " [-0.15464334]\n",
      " [-0.1681166 ]\n",
      " [-0.15914625]\n",
      " [-0.21004364]\n",
      " [-0.34276098]\n",
      " [-0.61797136]\n",
      " [-0.6116208 ]\n",
      " [-0.5823533 ]\n",
      " [-0.6523058 ]\n",
      " [-0.57598984]\n",
      " [-0.7231405 ]\n",
      " [-0.645217  ]\n",
      " [-0.7316857 ]\n",
      " [-0.6176261 ]\n",
      " [-0.66819793]\n",
      " [-0.72829586]\n",
      " [-0.6225373 ]\n",
      " [-0.6421714 ]\n",
      " [-0.68434393]\n",
      " [-0.6771545 ]\n",
      " [-0.78311497]\n",
      " [-0.76454955]\n",
      " [-0.67367685]\n",
      " [-0.7398642 ]\n",
      " [-0.75965244]\n",
      " [-1.1369727 ]\n",
      " [-1.1275463 ]\n",
      " [-1.4134991 ]\n",
      " [-1.3386405 ]\n",
      " [-1.3990484 ]\n",
      " [-1.3614236 ]\n",
      " [-1.328767  ]\n",
      " [-1.3790824 ]\n",
      " [-1.3005188 ]\n",
      " [-1.2970465 ]\n",
      " [-1.1606054 ]\n",
      " [-1.139837  ]\n",
      " [-1.1537274 ]\n",
      " [-1.3386024 ]\n",
      " [-1.3519741 ]\n",
      " [-1.2461499 ]\n",
      " [-1.4061027 ]\n",
      " [-1.4006891 ]\n",
      " [-1.6173537 ]\n",
      " [-1.5218683 ]\n",
      " [-1.6728994 ]\n",
      " [-1.5210538 ]\n",
      " [-1.5462565 ]\n",
      " [-1.449204  ]\n",
      " [-1.6407533 ]\n",
      " [-1.5660971 ]\n",
      " [-1.6192179 ]\n",
      " [-1.4758942 ]\n",
      " [-1.7001954 ]\n",
      " [-1.7686414 ]\n",
      " [-1.8225518 ]\n",
      " [-1.8694574 ]], shape=(135, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.800151  ]\n",
      " [ 0.82862574]\n",
      " [ 0.8436978 ]\n",
      " [ 0.87261236]\n",
      " [ 0.8470576 ]\n",
      " [ 0.87600607]\n",
      " [ 0.8504856 ]\n",
      " [ 0.8794687 ]\n",
      " [ 0.9087446 ]\n",
      " [ 0.9109355 ]\n",
      " [ 0.9405293 ]\n",
      " [ 0.97042185]\n",
      " [ 1.0006164 ]\n",
      " [ 1.031116  ]\n",
      " [ 1.0208527 ]\n",
      " [ 1.0241761 ]\n",
      " [ 1.0412234 ]\n",
      " [ 1.0447524 ]\n",
      " [ 1.0756978 ]\n",
      " [ 1.0248137 ]\n",
      " [ 1.0555577 ]\n",
      " [ 1.0592316 ]\n",
      " [ 1.0903233 ]\n",
      " [ 1.1080388 ]\n",
      " [ 0.94795865]\n",
      " [ 0.964236  ]\n",
      " [ 0.9669874 ]\n",
      " [ 0.9971474 ]\n",
      " [ 0.9728506 ]\n",
      " [ 0.97568905]\n",
      " [ 1.005937  ]\n",
      " [ 1.0364903 ]\n",
      " [ 1.0673522 ]\n",
      " [ 1.0711453 ]\n",
      " [ 1.047596  ]\n",
      " [ 0.9416667 ]\n",
      " [ 0.9441902 ]\n",
      " [ 0.97411984]\n",
      " [ 1.0043517 ]\n",
      " [ 0.788463  ]\n",
      " [ 0.73467755]\n",
      " [ 0.6529681 ]\n",
      " [ 0.6799561 ]\n",
      " [ 0.66614556]\n",
      " [ 0.69326675]\n",
      " [ 0.7206617 ]\n",
      " [ 0.7346432 ]\n",
      " [ 0.7350755 ]\n",
      " [ 0.7628929 ]\n",
      " [ 0.79099125]\n",
      " [ 0.8193735 ]\n",
      " [ 0.8206617 ]\n",
      " [ 0.79458225]\n",
      " [ 0.8093104 ]\n",
      " [ 0.81049687]\n",
      " [ 0.78431463]\n",
      " [ 0.79893893]\n",
      " [ 0.7863304 ]\n",
      " [ 0.7599041 ]\n",
      " [ 0.6510688 ]\n",
      " [ 0.650657  ]\n",
      " [ 0.6776216 ]\n",
      " [ 0.69116825]\n",
      " [ 0.6911614 ]\n",
      " [ 0.70484495]\n",
      " [ 0.5954535 ]\n",
      " [ 0.6218605 ]\n",
      " [ 0.64853436]\n",
      " [ 0.56595486]\n",
      " [ 0.5920639 ]\n",
      " [ 0.5910561 ]\n",
      " [ 0.39837337]\n",
      " [-0.01530118]\n",
      " [-0.00875361]\n",
      " [-0.01583041]\n",
      " [ 0.00440214]\n",
      " [-0.08468375]\n",
      " [-0.14728878]\n",
      " [-0.14207451]\n",
      " [-0.13680749]\n",
      " [-0.11779698]\n",
      " [-0.09859455]\n",
      " [-0.1887209 ]\n",
      " [-0.3892803 ]\n",
      " [-0.41389108]\n",
      " [-0.5208925 ]\n",
      " [-0.6152844 ]\n",
      " [-0.6284877 ]\n",
      " [-0.6418244 ]\n",
      " [-0.68267643]\n",
      " [-0.68287015]\n",
      " [-0.6967561 ]\n",
      " [-0.68340164]\n",
      " [-0.6699123 ]\n",
      " [-0.65628666]\n",
      " [-0.65621376]\n",
      " [-0.68352085]\n",
      " [-0.6974133 ]\n",
      " [-0.7388269 ]\n",
      " [-0.7258974 ]\n",
      " [-0.740218  ]\n",
      " [-0.86420596]\n",
      " [-0.852543  ]\n",
      " [-0.9639752 ]\n",
      " [-0.98070055]\n",
      " [-1.1892598 ]\n",
      " [-1.1808801 ]\n",
      " [-1.1861061 ]\n",
      " [-1.2050753 ]\n",
      " [-1.1968552 ]\n",
      " [-1.1885524 ]\n",
      " [-1.2075462 ]\n",
      " [-1.1993512 ]\n",
      " [-1.2184541 ]\n",
      " [-1.2651308 ]\n",
      " [-1.2848982 ]\n",
      " [-1.3322458 ]\n",
      " [-1.4348333 ]\n",
      " [-1.4426244 ]\n",
      " [-1.436804  ]\n",
      " [-1.4856862 ]\n",
      " [-1.5898235 ]\n",
      " [-1.5991803 ]\n",
      " [-1.622322  ]\n",
      " [-1.6456972 ]\n",
      " [-1.6556184 ]\n",
      " [-1.6793302 ]\n",
      " [-1.7580427 ]\n",
      " [-1.7554084 ]\n",
      " [-1.7664378 ]\n",
      " [-1.7912687 ]\n",
      " [-1.8163507 ]\n",
      " [-1.9922796 ]\n",
      " [-1.9920114 ]\n",
      " [-1.9917402 ]], shape=(135, 1), dtype=float32)\n",
      "------------------------finished game--------------------------\n",
      "loss: tf.Tensor(0.6710477, shape=(), dtype=float32)\n",
      "this was our episode_reward: tf.Tensor(1628.0, shape=(), dtype=float32)\n",
      "Model: \"actor_critic_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  1028      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  257       \n",
      "=================================================================\n",
      "Total params: 67,077\n",
      "Trainable params: 67,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "TESTING = False\n",
    "######################################\n",
    "if TESTING:\n",
    "    runtest()\n",
    "    while True:\n",
    "        continue\n",
    "if not TRAINING:\n",
    "    PATH = \"/Users/weston/bin/chromedriver\"\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "model = ActorCritic(4, 256, 12)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "gamma = 0.99\n",
    "n = 0\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "if not TRAINING:\n",
    "    loadsite()\n",
    "while True:\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint is None:\n",
    "        loss = open(\"loss.csv\", \"w\")\n",
    "        loss.truncate(0)\n",
    "        criticloss = open(\"criticloss.csv\", \"w\")\n",
    "        criticloss.truncate(0)\n",
    "        episodereward = open(\"episodereward.csv\", \"w\")\n",
    "        episodereward.truncate(0)\n",
    "    train_step(model, opt, gamma, n)\n",
    "    n += 1\n",
    "    if not TRAINING:\n",
    "        showstats()\n",
    "    model.summary()\n",
    "    save_path = manager.save()\n",
    "    if not TRAINING:\n",
    "        bar(1)\n",
    "        print(\"model saved\")\n",
    "        bar(1)\n",
    "        restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
